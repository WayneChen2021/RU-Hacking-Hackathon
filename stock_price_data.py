# -*- coding: utf-8 -*-
"""stock price data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sEJQfRVgAkkhJQBOnxl1hZ0cSCP4AaOk
"""

!pip install yfinance
!pip install yahoofinancials

import zipfile #Import this if you need to unzip the SEC data
import json as js
import os
import yfinance as yf
from yahoofinancials import YahooFinancials
import datetime

from google.colab import drive
drive.mount('/content/drive')

#Uncomment this if you need to unzip the SEC data (make sure to change the paths).
'''
with zipfile.ZipFile("/content/drive/MyDrive/stock_price_hackathon/sec_data.zip", 'r') as zip_ref:
    zip_ref.extractall("/content/drive/MyDrive/stock_price_hackathon")
'''

def is_float(element):
    try:
        float(element)
        return True
    except ValueError:
        return False

json = {}
tags = {}
tag_counter = 0

for year in range(9,23):
    for quarter in range(1,5):
        year_str = str(year)
        if year == 9:
            year_str = '09'
        path_part = '20' + year_str + 'q' + str(quarter)

        #This will become the path to one of the sub.txt files (change as necessary)
        path_sub = "/content/drive/MyDrive/stock_price_hackathon/sec_data/{}/sub.txt".format(path_part)

        #This will become the path to one of the num.txt files (change as necessary)
        path_num = "/content/drive/MyDrive/stock_price_hackathon/sec_data/{}/num.txt".format(path_part)

        if os.path.isfile(path_sub):
            processed_companies = {}
            num_to_ticker = {}

            with open(path_sub, "r") as f:
                for i, l in enumerate(f):
                    if i != 0:
                        content = l.split()
                        displace = -1
                        while not ".xml" in content[displace]:
                            displace -= 1
                        xml = content[displace]
                        if ".xml" in xml:
                            ticker = xml[:xml.find('-')]
                            if ticker.isalpha() and ticker.islower():
                                num_to_ticker[content[0][:10].lstrip('0')] = ticker

            with open(path_num, "r") as f:
                for i, line in enumerate(f):
                    if i != 0:
                        try:
                            info = line.split()
                            edgar_num = info[0][:10].lstrip('0')
                            if not edgar_num in processed_companies:
                                processed_companies[edgar_num] = num_to_ticker[edgar_num]

                            ticker = processed_companies[edgar_num]
                            if not ticker in json:
                                json[ticker] = {}

                            company_data = json[ticker]
                            if info[3].isnumeric():
                                date = info[3][:4] + '-' + info[3][4:6] + '-' + info[3][6:]
                                if not date in company_data:
                                    company_data[date] = {}

                                statement_data = company_data[date]
                                tag = info[1]
                                if not tag in tags:
                                    tags[tag] = [str(tag_counter), "0"]
                                    tag_counter += 1
                                tag_tup = tags[tag]
                                tag_tup[1] = str(int(tag_tup[1]) + 1)

                                displace = -1
                                while not ("." in info[displace] and is_float(info[displace])) and displace > -1*len(info):
                                    displace -= 1

                                statement_data[tag_tup[0]] = str(int(float(info[displace])))
                        except KeyboardInterrupt:
                            raise KeyboardInterrupt
                        except:
                            pass

#Change path to location where the SEC data (as a JSON) will be stored
with open("/content/drive/MyDrive/stock_price_hackathon/data.txt", "w") as data_file:
    data_file.write(js.dumps(json))

#Change path to location where the SEC statement fields (i.e "net income", "accounts receivable") will be stored
with open("/content/drive/MyDrive/stock_price_hackathon/tags.txt", "w") as tag_file:
    tag_file.write(js.dumps(tags))

#Change path to where the SEC data JSON was stored
with open("/content/drive/MyDrive/stock_price_hackathon/data.txt", "r") as data_file:
    data = js.loads(data_file.read())

for ticker in data:
    statements = data[ticker]
    df = yf.download(ticker.upper())
    if len(list(yf.shared._ERRORS.keys())) == 0:
        df = df.reset_index()
        price_0 = "0"
        for date in statements:
            d = datetime.datetime.fromisoformat(date)
            if d.date() < datetime.datetime.today().date():
                try:
                    d = (d + datetime.timedelta(days=1))
                    while (d.date() < datetime.datetime.today().date() and not any(df.Date == d.isoformat()[:10])):
                        d = (d + datetime.timedelta(days=1))
                    price = str(float(df.loc[df['Date'] == d.isoformat()[:10]]['Close']))
                    statements[date]["-1"] = price
                    print(ticker + " " + date + " " + price)
                except KeyboardInterrupt:
                    raise KeyboardInterrupt
                except:
                    pass

#Change to path where JSON with SEC data and stock prices will be stored
with open("/content/drive/MyDrive/stock_price_hackathon/with_prices.txt", "w") as with_price_file:
    with_price_file.write(js.dumps(data))

#Change to path where JSON with SEC data and stock prices was stored
with open("/content/drive/MyDrive/stock_price_hackathon/with_prices.txt", "r") as with_price_file:
    data = js.loads(with_price_file.read())

#Change path to location where the SEC statement fields (i.e "net income", "accounts receivable") was stored
with open("/content/drive/MyDrive/stock_price_hackathon/tags.txt", "r") as tag_file:
    tag_data = js.loads(tag_file.read())

tags_sorted_popular = sorted(tag_data.items(), key=lambda x: int(x[1][1]), reverse=True)
NUM_TAGS = 40 #determines the number of fields in the statments that we care about; increasing this gives less training data
new_data = {}
ok_tags = [tup[1][0] for tup in tags_sorted_popular[:NUM_TAGS]]

for ticker in data:
    new_company_data = {}
    company_data = data[ticker]
    for date in company_data:
        new_statement = {}
        statement = company_data[date]
        if not "-1" in statement or float(statement["-1"]) <= 0:
            break
        canAppend = True
        for tag in ok_tags:
            if not tag in statement:
                canAppend = False
                break

        if canAppend:
            new_statement = statement

        if len(new_statement):
            new_company_data[date] = new_statement

    if len(new_company_data) > 1:
        new_data[ticker] = new_company_data

#Change to path where the checked JSON with SEC data and stock prices will be stored
with open("/content/drive/MyDrive/stock_price_hackathon/checked_data.txt", "w") as checked_file:
    checked_file.write(js.dumps(new_data))

#Change to path where the fields from the statements that will be used will be stored
with open("/content/drive/MyDrive/stock_price_hackathon/final_tags.txt", "w") as final_tags:
    final_tags.write(js.dumps(ok_tags))
